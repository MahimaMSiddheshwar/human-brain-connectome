{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 05: Graph Analysis\n",
    "\n",
    "Compute node-level and global network metrics, and identify community structure."
   ]
  },
  {
   "cell_type": {"metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "import json\n",
    "from networkx.algorithms import community\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ All required libraries imported successfully\")"
   ]
  },
  {
   "cell_type": {"metadata": {},\n",
   "execution_count": null,\n",
   "outputs": [],\n",
    "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✓ Random seed set to 42\")"
   ]
  },
  {
   "cell_type": {"metadata": {},\n",
   "execution_count": null,\n",
   "outputs": [],\n",
    "source": [
    "# Define paths\n",
    "notebook_dir = Path.cwd()\n",
    "project_dir = notebook_dir.parent\n",
    "data_dir = project_dir / 'data'\n",
    "results_dir = project_dir / 'results'\n",
    "\n",
    "# Load config\n",
    "config_path = data_dir / 'config.json'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(f\"✓ Configuration loaded\")"
   ]
  },
  {
   "cell_type": {"metadata": {},\n",
   "execution_count": null,\n",
   "outputs": [],\n",
    "source": [
    "# Load human_connectome.graphml\n",
    "print(\"Loading connectome graph...\")\n",
    "graphml_path = results_dir / 'human_connectome.graphml'\n",
    "G = nx.read_graphml(str(graphml_path))\n",
    "\n",
    "# Convert node names to integers (NetworkX stores them as strings by default)\n",
    "G = nx.convert_node_labels_to_integers(G)\n",
    "\n",
    "print(f\"✓ Graph loaded successfully\")\n",
    "print(f\"  Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"  Edges: {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": {"metadata": {},\n",
   "execution_count": null,\n",
   "outputs": [],\n",
    "source": [
    "# Compute node-level metrics for every node\n",
    "print(\"\\nComputing node-level centrality metrics...\")\n",
    "\n",
    "# Betweenness centrality with weight\n",
    "print(\"  Computing betweenness centrality...\")\n",
    "betweenness = nx.betweenness_centrality(G, weight='weight')\n",
    "\n",
    "# Degree centrality\n",
    "print(\"  Computing degree centrality...\")\n",
    "degree_cent = nx.degree_centrality(G)\n",
    "\n",
    "# PageRank with weight\n",
    "print(\"  Computing PageRank...\")\n",
    "pagerank = nx.pagerank(G, alpha=0.85, weight='weight')\n",
    "\n",
    "# Clustering coefficient with weight\n",
    "print(\"  Computing clustering coefficient...\")\n",
    "clustering = nx.clustering(G, weight='weight')\n",
    "\n",
    "# Strength (sum of weighted edges)\n",
    "print(\"  Computing node strength...\")\n",
    "strength = {}\n",
    "for node in G.nodes():\n",
    "    strength[node] = sum([G[node][neighbor]['weight'] for neighbor in G.neighbors(node)])\n",
    "\n",
    "print(\"✓ All metrics computed\")"
   ]
  },
  {
   "cell_type": {"metadata": {},\n",
   "execution_count": null,\n",
   "outputs": [],\n",
    "source": [
    "# Create a results DataFrame with all metrics\n",
    "print(\"Creating results DataFrame...\")\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Region': [f'Region_{i+1}' for i in range(G.number_of_nodes())],\n",
    "    'Node': list(G.nodes()),\n",
    "    'Betweenness_Centrality': [betweenness[node] for node in G.nodes()],\n",
    "    'Degree_Centrality': [degree_cent[node] for node in G.nodes()],\n",
    "    'PageRank': [pagerank[node] for node in G.nodes()],\n",
    "    'Clustering_Coefficient': [clustering[node] for node in G.nodes()],\n",
    "    'Strength': [strength[node] for node in G.nodes()]\n",
    "})\n",
    "\n",
    "# Sort by betweenness centrality descending\n",
    "metrics_df = metrics_df.sort_values('Betweenness_Centrality', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f\"✓ Results DataFrame created\")\n",
    "print(f\"  Shape: {metrics_df.shape}\")"
   ]
  },
  {
   "cell_type": {"metadata": {},\n",
   "execution_count": null,\n",
   "outputs": [],\n",
    "source": [
    "# Print TOP 15 HUB REGIONS as a formatted table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 15 HUB REGIONS BY BETWEENNESS CENTRALITY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_hubs = metrics_df.head(15)\n",
    "print(\"\\nRank  Region              Betweenness  Degree    PageRank  Strength   Clustering\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for idx, row in top_hubs.iterrows():\n",
    "    print(f\"{idx+1:3d}   {row['Region']:18s}  {row['Betweenness_Centrality']:9.5f}  {row['Degree_Centrality']:8.5f}  {row['PageRank']:8.6f}  {row['Strength']:8.3f}   {row['Clustering_Coefficient']:7.4f}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": {"metadata": {},\n",
   "execution_count": null,\n",
   "outputs": [],\n",
    "source": [
    "# Save full results as results/hub_regions.csv\n",
    "print(\"\\nSaving metrics to CSV...\")\n",
    "csv_path = results_dir / 'hub_regions.csv'\n",
    "metrics_df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"✓ Metrics saved to {csv_path}\")"
   ]
  },
  {
   "cell_type": {"metadata": {},\n",
   "execution_count": null,\n",
   "outputs": [],\n",
    "source": [
    "# Run greedy modularity community detection\n",
    "print(\"\\nDetecting modular community structure...\")\n",
    "\n",
    "# Use greedy modularity optimization for community detection\n",
    "communities_list = list(community.greedy_modularity_communities(G, weight='weight'))\n",
    "\n",
    "print(f\"✓ Community detection complete\")\n",
    "print(f\"  Number of communities found: {len(communities_list)}\")"
   ]
  },
  {
   "cell_type": {"metadata": {},\n",
   "execution_count": null,\n",
   "outputs": [],\n",
    "source": [
    "# Compute modularity Q score\n",
    "Q = community.modularity(G, communities_list, weight='weight')\n",
    "\n",
    "print(f\"\\nModularity Analysis:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Number of communities: {len(communities_list)}\")\n",
    "print(f\"  Modularity Q score: {Q:.4f}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": {"metadata": {},\n",
   "execution_count": null,\n",
   "outputs": [],\n",
    "source": [
    "# Print members of each community\n",
    "print(f\"\\nCommunity Composition:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "community_mapping = {}  # For saving later\n",
    "\n",
    "for comm_idx, comm_nodes in enumerate(communities_list):\n",
    "    comm_nodes_sorted = sorted(list(comm_nodes))\n",
    "    print(f\"\\nCommunity {comm_idx + 1}: {len(comm_nodes)} regions\")\n",
    "    print(f\"  Nodes: {comm_nodes_sorted[:10]}\", end=\"\")\n",
    "    if len(comm_nodes_sorted) > 10:\n",
    "        print(f\", ... ({len(comm_nodes_sorted) - 10} more)\")\n",
    "    else:\n",
    "        print()\n",
    "    \n",
    "    # Store mapping\n",
    "    for node in comm_nodes_sorted:\n",
    "        community_mapping[str(node)] = comm_idx\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": {"metadata": {},\n",
   "execution_count": null,\n",
   "outputs": [],\n",
    "source": [
    "# Compute global network properties\n",
    "print(\"\\nComputing global network properties...\")\n",
    "\n",
    "# Density\n",
    "density = nx.density(G)\n",
    "\n",
    "# Average clustering coefficient\n",
    "avg_clustering = nx.average_clustering(G, weight='weight')\n",
    "\n",
    "# Number of connected components\n",
    "n_components = nx.number_connected_components(G)\n",
    "\n",
    "# Average path length (for largest connected component)\n",
    "largest_cc = max(nx.connected_components(G), key=len)\n",
    "G_subgraph = G.subgraph(largest_cc)\n",
    "avg_path_length = nx.average_shortest_path_length(G_subgraph)\n",
    "\n",
    "# Global efficiency\n",
    "reciprocal_paths = []\n",
    "for source in G_subgraph.nodes():\n",
    "    lengths = nx.single_source_shortest_path_length(G_subgraph, source)\n",
    "    for target, length in lengths.items():\n",
    "        if length > 0:\n",
    "            reciprocal_paths.append(1.0 / length)\n",
    "\n",
    "n_nodes = G_subgraph.number_of_nodes()\n",
    "global_efficiency = sum(reciprocal_paths) / (n_nodes * (n_nodes - 1))\n",
    "\n",
    "print(f\"✓ Global properties computed\")"
   ]
  },
  {
   "cell_type": {"metadata": {},\n",
   "execution_count": null,\n",
   "outputs": [],\n",
    "source": [
    "# Print global network properties\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GLOBAL NETWORK PROPERTIES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBasic Properties:\")\n",
    "print(f\"  Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"  Edges: {G.number_of_edges()}\")\n",
    "print(f\"  Density: {density:.4f}\")\n",
    "print(f\"\\nConnectivity:\")\n",
    "print(f\"  Connected components: {n_components}\")\n",
    "print(f\"  Largest component size: {len(largest_cc)}\")\n",
    "print(f\"\\nClustering:\")\n",
    "print(f\"  Average clustering coefficient: {avg_clustering:.4f}\")\n",
    "print(f\"\\nPath-based Metrics:\")\n",
    "print(f\"  Average path length: {avg_path_length:.4f}\")\n",
    "print(f\"  Global efficiency: {global_efficiency:.4f}\")\n",
    "print(f\"\\nCommunity Structure:\")\n",
    "print(f\"  Number of communities: {len(communities_list)}\")\n",
    "print(f\"  Modularity Q: {Q:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": {"metadata": {},\n",
   "execution_count": null,\n",
   "outputs": [],\n",
    "source": [
    "# Save community assignments as results/communities.json\n",
    "print(\"\\nSaving community assignments...\")\n",
    "\n",
    "communities_data = {\n",
    "    'n_communities': len(communities_list),\n",
    "    'modularity_Q': float(Q),\n",
    "    'communities': [\n",
    "        {\n",
    "            'id': i,\n",
    "            'size': len(comm),\n",
    "            'nodes': sorted([int(n) for n in comm])\n",
    "        }\n",
    "        for i, comm in enumerate(communities_list)\n",
    "    ],\n",
    "    'node_community_mapping': community_mapping,\n",
    "    'global_properties': {\n",
    "        'density': float(density),\n",
    "        'avg_clustering_coefficient': float(avg_clustering),\n",
    "        'n_connected_components': int(n_components),\n",
    "        'avg_path_length': float(avg_path_length),\n",
    "        'global_efficiency': float(global_efficiency)\n",
    "    }\n",
    "}\n",
    "\n",
    "communities_path = results_dir / 'communities.json'\n",
    "with open(communities_path, 'w') as f:\n",
    "    json.dump(communities_data, f, indent=4)\n",
    "\n",
    "print(f\"✓ Community assignments saved to {communities_path}\")"
   ]
  },
  {
   "cell_type": {"metadata": {},\n",
   "execution_count": null,\n",
   "outputs": [],\n",
    "source": [
    "# Print completion summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GRAPH ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nNode-level metrics computed for {G.number_of_nodes()} regions\")\n",
    "print(f\"\\nFiles saved:\")\n",
    "print(f\"  Hub regions: {csv_path}\")\n",
    "print(f\"  Communities: {communities_path}\")\n",
    "print(f\"\\nNext Step: Run Notebook 06 (Visualization)\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
