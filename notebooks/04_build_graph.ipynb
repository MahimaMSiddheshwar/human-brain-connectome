{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 04: Build Connectome Graph\n",
    "\n",
    "This notebook converts the functional connectivity matrix into a NetworkX graph structure. A connectome graph represents brain regions as nodes and their functional connections as edges. The graph enables network analysis including centrality measures, community detection, and global network properties.\n",
    "\n",
    "Key steps:\n",
    "1. Load functional connectivity matrix from Notebook 03\n",
    "2. Apply correlation threshold to define significant connections\n",
    "3. Build NetworkX graph from thresholded connectivity matrix\n",
    "4. Compute and visualize network statistics\n",
    "5. Save graph in GraphML format for future use\n",
    "6. Create degree distribution visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries for graph analysis\n",
    "# numpy: numerical operations and array manipulation\n",
    "# pandas: data structures and analysis\n",
    "# json: load configuration\n",
    "# Path: cross-platform file path handling\n",
    "# networkx: graph/network analysis and algorithms\n",
    "# scipy: correlation and scientific computing\n",
    "# matplotlib: visualization\n",
    "# numpy.ma: masked array operations for handling NaN values\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "from scipy.stats import threshold\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All required libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "# Ensures consistent results across multiple runs\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Random seed set to 42 for reproducibility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration and set up directory paths\n",
    "notebook_dir = Path.cwd()\n",
    "project_dir = notebook_dir.parent\n",
    "data_dir = project_dir / 'data'\n",
    "results_dir = project_dir / 'results'\n",
    "figures_dir = project_dir / 'figures'\n",
    "\n",
    "# Load config.json containing dataset parameters\n",
    "config_path = data_dir / 'config.json'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "n_regions = config['n_regions']\n",
    "\n",
    "print(f\"Configuration loaded from {config_path}\")\n",
    "print(f\"Number of brain regions: {n_regions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the functional connectivity matrix from Notebook 03\n",
    "# This matrix represents pairwise correlation strengths between all brain regions\n",
    "# Shape: (n_regions, n_regions)\n",
    "# Value at [i,j] = correlation coefficient between region i and region j\n",
    "\n",
    "connectivity_path = data_dir / 'functional_matrix.npy'\n",
    "print(f\"Loading functional connectivity matrix from {connectivity_path}\")\n",
    "\n",
    "functional_matrix = np.load(connectivity_path)\n",
    "\n",
    "print(f\"\\nFunctional Connectivity Matrix Properties:\")\n",
    "print(f\"  Shape: {functional_matrix.shape}\")\n",
    "print(f\"  Data type: {functional_matrix.dtype}\")\n",
    "print(f\"  Min value: {np.nanmin(functional_matrix):.4f}\")\n",
    "print(f\"  Max value: {np.nanmax(functional_matrix):.4f}\")\n",
    "print(f\"  Mean value: {np.nanmean(functional_matrix):.4f}\")\n",
    "print(f\"  Std value: {np.nanstd(functional_matrix):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply threshold to define significant connections\n",
    "# Thresholding is important because:\n",
    "# 1. Very weak correlations (r < 0.3) may be due to noise\n",
    "# 2. Creates sparsity - makes the graph more interpretable\n",
    "# 3. Focuses on biologically meaningful connections\n",
    "\n",
    "# Define threshold value\n",
    "correlation_threshold = 0.3\n",
    "print(f\"Applying correlation threshold: r > {correlation_threshold}\")\n",
    "print(f\"\\nThreshold rationale:\")\n",
    "print(f\"  - Removes weak correlations likely due to noise\")\n",
    "print(f\"  - Focuses on moderate-to-strong functional connections\")\n",
    "print(f\"  - Value of 0.3 is standard in resting-state fMRI analysis\")\n",
    "print(f\"  - Creates sparse graph for efficient computation\")\n",
    "\n",
    "# Create a copy to preserve original\n",
    "thresholded_matrix = functional_matrix.copy()\n",
    "\n",
    "# Set all correlations below threshold to 0\n",
    "# Keep diagonal as 0 (self-connections not meaningful)\n",
    "thresholded_matrix[np.abs(thresholded_matrix) < correlation_threshold] = 0\n",
    "np.fill_diagonal(thresholded_matrix, 0)  # Remove self-loops\n",
    "\n",
    "print(f\"\\nThresholding Results:\")\n",
    "# Count connections above threshold\n",
    "n_connections = np.sum(thresholded_matrix != 0)\n",
    "max_possible_connections = n_regions * (n_regions - 1)  # Exclude diagonal\n",
    "sparsity = n_connections / max_possible_connections\n",
    "\n",
    "print(f\"  Connections above threshold: {n_connections}\")\n",
    "print(f\"  Maximum possible connections: {max_possible_connections}\")\n",
    "print(f\"  Graph sparsity: {sparsity:.2%}\")\n",
    "print(f\"  Connectivity range: [{np.min(thresholded_matrix[thresholded_matrix!=0]):.4f}, {np.max(thresholded_matrix):.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build NetworkX graph from thresholded connectivity matrix\n",
    "# NetworkX is a Python library for analyzing complex networks\n",
    "# A Graph object stores nodes (brain regions) and edges (connections)\n",
    "\n",
    "print(\"Building NetworkX graph from connectivity matrix...\")\n",
    "\n",
    "# Create empty undirected graph\n",
    "# Undirected: connections are bidirectional (if A connects to B, B connects to A)\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add all regions as nodes\n",
    "# Each node represents one brain region\n",
    "G.add_nodes_from(range(n_regions))\n",
    "\n",
    "# Add edges for all connections above threshold\n",
    "# Iterate through upper triangle of matrix (avoid duplicates)\n",
    "for i in range(n_regions):\n",
    "    for j in range(i+1, n_regions):\n",
    "        # Check if connection strength exceeds threshold\n",
    "        connection_strength = thresholded_matrix[i, j]\n",
    "        if connection_strength > 0:\n",
    "            # Add edge with weight equal to correlation strength\n",
    "            # Weight can be used for weighted network analysis\n",
    "            G.add_edge(i, j, weight=connection_strength)\n",
    "\n",
    "print(f\"Graph construction complete\")\n",
    "print(f\"\\nGraph Properties:\")\n",
    "print(f\"  Number of nodes: {G.number_of_nodes()}\")\n",
    "print(f\"  Number of edges: {G.number_of_edges()}\")\n",
    "print(f\"  Graph density: {nx.density(G):.4f}\")\n",
    "print(f\"    (Density = edges / max_edges, ranges 0-1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute graph connectivity statistics\n",
    "# These metrics describe the overall structure of the network\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GRAPH STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Compute degree for each node\n",
    "# Degree = number of connections for a node\n",
    "degree_list = dict(G.degree())\n",
    "degree_values = list(degree_list.values())\n",
    "\n",
    "print(f\"\\nDegree Statistics:\")\n",
    "print(f\"  Mean degree: {np.mean(degree_values):.2f}\")\n",
    "print(f\"  Median degree: {np.median(degree_values):.2f}\")\n",
    "print(f\"  Min degree: {np.min(degree_values)}\")\n",
    "print(f\"  Max degree: {np.max(degree_values)}\")\n",
    "print(f\"  Std dev: {np.std(degree_values):.2f}\")\n",
    "\n",
    "# Compute number of connected components\n",
    "# A connected component is a group of nodes that are connected to each other\n",
    "n_components = nx.number_connected_components(G)\n",
    "print(f\"\\nConnectivity:\")\n",
    "print(f\"  Number of connected components: {n_components}\")\n",
    "if n_components == 1:\n",
    "    print(f\"  Status: Network is fully connected\")\n",
    "    is_connected = True\n",
    "else:\n",
    "    print(f\"  Status: Network has {n_components} disconnected subnetworks\")\n",
    "    is_connected = False\n",
    "    # Show sizes of each component\n",
    "    components = list(nx.connected_components(G))\n",
    "    component_sizes = [len(c) for c in components]\n",
    "    print(f\"  Component sizes: {sorted(component_sizes, reverse=True)}\")\n",
    "\n",
    "# Compute clustering coefficient\n",
    "# Measures how likely it is that neighbors of a node are also connected\n",
    "# Range: 0-1 (0=no clustering, 1=complete clustering)\n",
    "avg_clustering = nx.average_clustering(G)\n",
    "print(f\"\\nNetwork Structure:\")\n",
    "print(f\"  Average clustering coefficient: {avg_clustering:.4f}\")\n",
    "print(f\"    (Measures how tightly grouped neighbors are)\")\n",
    "\n",
    "# Compute average shortest path length (if connected)\n",
    "if is_connected:\n",
    "    avg_path_length = nx.average_shortest_path_length(G)\n",
    "    print(f\"  Average shortest path length: {avg_path_length:.2f}\")\n",
    "    print(f\"    (Average steps between any two regions)\")\n",
    "    \n",
    "    # Compute network diameter\n",
    "    diameter = nx.diameter(G)\n",
    "    print(f\"  Network diameter: {diameter}\")\n",
    "    print(f\"    (Maximum shortest path in network)\")\n",
    "else:\n",
    "    print(f\"  Average shortest path length: Not computed (disconnected graph)\")\n",
    "    print(f\"  Network diameter: Not computed (disconnected graph)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save graph in GraphML format for use in other notebooks\n",
    "# GraphML is an XML-based format that preserves all graph information\n",
    "# Advantages: human-readable, preserves node/edge attributes, widely supported\n",
    "\n",
    "graph_output_path = results_dir / 'connectome_graph.graphml'\n",
    "nx.write_graphml(G, graph_output_path)\n",
    "\n",
    "print(f\"\\nGraph saved to: {graph_output_path}\")\n",
    "print(f\"File size: {graph_output_path.stat().st_size / 1024:.2f} KB\")\n",
    "\n",
    "# Also save the thresholded connectivity matrix for reference\n",
    "connectivity_output_path = results_dir / 'thresholded_connectivity_matrix.npy'\n",
    "np.save(connectivity_output_path, thresholded_matrix)\n",
    "print(f\"\\nThresholded connectivity matrix saved to: {connectivity_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create degree distribution visualization\n",
    "# The degree distribution shows how many nodes have each degree value\n",
    "# Important for understanding network organization\n",
    "\n",
    "print(\"Creating degree distribution visualization...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Brain Connectome Network Analysis', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 1: Degree distribution histogram\n",
    "# Shows frequency distribution of node degrees\n",
    "ax = axes[0, 0]\n",
    "ax.hist(degree_values, bins=20, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax.axvline(np.mean(degree_values), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(degree_values):.2f}')\n",
    "ax.set_xlabel('Node Degree')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Degree Distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 2: Cumulative degree distribution\n",
    "# Shows what proportion of nodes have degree <= each value\n",
    "ax = axes[0, 1]\n",
    "sorted_degrees = sorted(degree_values)\n",
    "cumulative = np.arange(1, len(sorted_degrees) + 1) / len(sorted_degrees)\n",
    "ax.plot(sorted_degrees, cumulative, marker='o', markersize=4, linestyle='-', linewidth=2, color='darkgreen')\n",
    "ax.set_xlabel('Node Degree')\n",
    "ax.set_ylabel('Cumulative Proportion')\n",
    "ax.set_title('Cumulative Degree Distribution')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Connection strength distribution\n",
    "# Shows the distribution of edge weights (correlation strengths)\n",
    "ax = axes[1, 0]\n",
    "edge_weights = [G[u][v]['weight'] for u, v in G.edges()]\n",
    "ax.hist(edge_weights, bins=30, color='coral', alpha=0.7, edgecolor='black')\n",
    "ax.axvline(np.mean(edge_weights), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(edge_weights):.3f}')\n",
    "ax.set_xlabel('Edge Weight (Correlation)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Connection Strength Distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: Network summary statistics\n",
    "# Display key metrics as text\n",
    "ax = axes[1, 1]\n",
    "ax.axis('off')\n",
    "\n",
    "summary_text = f\"\"\"NETWORK STATISTICS SUMMARY\n",
    "\n",
    "Basic Properties:\n",
    "  Nodes: {G.number_of_nodes()}\n",
    "  Edges: {G.number_of_edges()}\n",
    "  Density: {nx.density(G):.4f}\n",
    "\n",
    "Degree:\n",
    "  Mean: {np.mean(degree_values):.2f}\n",
    "  Median: {np.median(degree_values):.2f}\n",
    "  Range: {np.min(degree_values)}-{np.max(degree_values)}\n",
    "\n",
    "Structure:\n",
    "  Clustering coeff: {avg_clustering:.4f}\n",
    "  Connected comp: {n_components}\n",
    "  Threshold: r > {correlation_threshold}\n",
    "\n",
    "Edge Weights:\n",
    "  Mean: {np.mean(edge_weights):.4f}\n",
    "  Range: {np.min(edge_weights):.4f}-{np.max(edge_weights):.4f}\n",
    "\"\"\"\n",
    "\n",
    "ax.text(0.1, 0.95, summary_text, transform=ax.transAxes, \n",
    "        fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_path = figures_dir / 'connectome_graph_analysis.png'\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"Visualization saved to {plot_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final summary of graph analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONNECTOME GRAPH CONSTRUCTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nInput Data:\")\n",
    "print(f\"  Functional connectivity matrix shape: {functional_matrix.shape}\")\n",
    "print(f\"  Correlation range: [{np.nanmin(functional_matrix):.4f}, {np.nanmax(functional_matrix):.4f}]\")\n",
    "\n",
    "print(f\"\\nThresholding Details:\")\n",
    "print(f\"  Threshold method: Absolute correlation > 0.3\")\n",
    "print(f\"  Rationale: Removes weak correlations (noise), focuses on strong connections\")\n",
    "print(f\"  Self-loops: Removed (diagonal set to 0)\")\n",
    "print(f\"  Resulting edges: {G.number_of_edges()} connections\")\n",
    "\n",
    "print(f\"\\nGraph Structure:\")\n",
    "print(f\"  Type: Undirected, weighted network\")\n",
    "print(f\"  Nodes: {G.number_of_nodes()} brain regions\")\n",
    "print(f\"  Edges: {G.number_of_edges()} functional connections\")\n",
    "print(f\"  Density: {nx.density(G):.4f} ({nx.density(G)*100:.2f}% of possible connections)\")\n",
    "\n",
    "print(f\"\\nNetwork Properties:\")\n",
    "print(f\"  Average degree: {np.mean(degree_values):.2f}\")\n",
    "print(f\"  Clustering coefficient: {avg_clustering:.4f}\")\n",
    "print(f\"  Connected components: {n_components}\")\n",
    "if is_connected:\n",
    "    print(f\"  Average path length: {avg_path_length:.2f}\")\n",
    "    print(f\"  Diameter: {diameter}\")\n",
    "\n",
    "print(f\"\\nWhat This Graph Represents:\")\n",
    "print(f\"  - NODES: Brain regions (Destrieux atlas, n={n_regions})\")\n",
    "print(f\"  - EDGES: Functional connections (Pearson correlation > 0.3)\")\n",
    "print(f\"  - WEIGHTS: Strength of functional coupling (correlation values)\")\n",
    "print(f\"\\nBiological Interpretation:\")\n",
    "print(f\"  - Connectome shows functional organization of brain\")\n",
    "print(f\"  - Hubs (high degree) = integrative regions\")\n",
    "print(f\"  - High clustering = local specialization\")\n",
    "print(f\"  - Low path length = global integration\")\n",
    "\n",
    "print(f\"\\nOutput Files:\")\n",
    "print(f\"  Graph (GraphML): {graph_output_path}\")\n",
    "print(f\"  Thresholded matrix: {connectivity_output_path}\")\n",
    "print(f\"  Visualization: {plot_path}\")\n",
    "\n",
    "print(f\"\\nNext Steps:\")\n",
    "print(f\"  1. Compute network centrality measures (Notebook 05)\")\n",
    "print(f\"  2. Identify hub regions\")\n",
    "print(f\"  3. Detect community structure\")\n",
    "print(f\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-application/json",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
